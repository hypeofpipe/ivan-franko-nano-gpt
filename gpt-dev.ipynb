{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1991e0d-d570-46be-811f-397d51dcee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file to inspect it\n",
    "\n",
    "with open('combined.txt', 'r', encoding='utf-') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d852454-e2dd-4dff-9fa0-4fef1fbcc135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in chars:  851155\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in chars: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4a48a8-9147-46e5-808b-2a8001a82b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boa constriktor\n",
      "Іван Франко\n",
      "ПОВІСТЬ\n",
      "Герман Гольдкремер встав нині дуже злий. Він все такий, кілько разів йому лучається ночувати в Бориславі. А лучається то щотижня раз, в п'ятницю, коли приїздить сюди з Дрогобича оглянути роботу і виплатити ріпникам. Герман Гольдкремер, хоть маєток його доходить до мільйона, ніколи не звірюе чужим очам надзору ані чужим рукам виплати. У нього в Дрогобичі своя камениця, порядна, нова, ясна, — сказати не жаль. А тут приходиться йому ночувати в дерев'янім домику, серед магазинів, завалених бочками кип'ячки та величезними грудами воску. Правда, той домик, поставлений його коштом, все-таки найпорядніший і найкраще положений на весь Борислав, — але знов дарма річ рівняти його до дрогобицьких будинків. Хоть стіни білі і вікна ясні, та вид навкруги сумний, понурий, поганий: купи хворосту, купи глини, брудні магазини та ще брудніші помешкання людські. Ні зелені свіжої, ні виду всміхненого не побачиш. Воздух удушливий, загуслий від нафтового сопуху; у Германа в\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04de17ae-524b-4dbe-a071-2ae2735d17f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#'()*,-./0123456789:;=?ABCEFGHIJLMNOPRSTVWXZ[]^_abcdefghijklmnopqrstuvwxyz}áäêüćęłňřśšż́ЄІЇАБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёєії–—‘’“”•…№\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "# all the unique chars that occur in the text\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0293cc5e-9fee-42b7-afd4-27179d6db302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130, 126, 135, 144, 131, 1, 138, 134, 1, 136, 131, 127, 126, 127, 126]\n",
      "ти є файна жаба\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from chars to integers; naive tokenizer implementation\n",
    "stoi = {ch: i for i,ch in enumerate(chars)}\n",
    "itos = {i: ch for i,ch in enumerate(chars)} \n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: convert string to list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: convert list of integers back to string\n",
    "\n",
    "print(encode(\"дайте ми кебаба\"))\n",
    "print(decode(encode(\"ти є файна жаба\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2310e5-17b1-4204-aa0d-5cc0f0d9dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d00aec-31d1-4cf7-b440-37a16ddd78a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([851155]) torch.int64\n",
      "tensor([ 28,  66,  52,   1,  54,  66,  65,  70,  71,  69,  60,  62,  71,  66,\n",
      "         69,   0,  93, 128, 126, 139,   1, 115, 142, 126, 139, 136, 140,   0,\n",
      "        110, 109,  97,  93, 112, 113, 122,   0,  98, 131, 142, 138, 126, 139,\n",
      "          1,  98, 140, 137, 154, 130, 136, 142, 131, 138, 131, 142,   1, 128,\n",
      "        143, 144, 126, 128,   1, 139, 134, 139, 160,   1, 130, 145, 132, 131,\n",
      "          1, 133, 137, 134, 135,  11,   1,  97, 160, 139,   1, 128, 143, 131,\n",
      "          1, 144, 126, 136, 134, 135,   9,   1, 136, 160, 137, 154, 136, 140,\n",
      "          1, 142, 126, 133, 160, 128,   1, 135, 140, 138, 145,   1, 137, 145,\n",
      "        149, 126, 159, 144, 154, 143, 157,   1, 139, 140, 149, 145, 128, 126,\n",
      "        144, 134,   1, 128,   1,  96, 140, 142, 134, 143, 137, 126, 128, 160,\n",
      "         11,   1,  95,   1, 137, 145, 149, 126, 159, 144, 154, 143, 157,   1,\n",
      "        144, 140,   1, 151, 140, 144, 134, 132, 139, 157,   1, 142, 126, 133,\n",
      "          9,   1, 128,   1, 141,   5, 157, 144, 139, 134, 148, 156,   9,   1,\n",
      "        136, 140, 137, 134,   1, 141, 142, 134, 161, 133, 130, 134, 144, 154,\n",
      "          1, 143, 156, 130, 134,   1, 133,   1,  99, 142, 140, 129, 140, 127,\n",
      "        134, 149, 126,   1, 140, 129, 137, 157, 139, 145, 144, 134,   1, 142,\n",
      "        140, 127, 140, 144, 145,   1, 160,   1, 128, 134, 141, 137, 126, 144,\n",
      "        134, 144, 134,   1, 142, 160, 141, 139, 134, 136, 126, 138,  11,   1,\n",
      "         98, 131, 142, 138, 126, 139,   1,  98, 140, 137, 154, 130, 136, 142,\n",
      "        131, 138, 131, 142,   9,   1, 147, 140, 144, 154,   1, 138, 126, 159,\n",
      "        144, 140, 136,   1, 135, 140, 129, 140,   1, 130, 140, 147, 140, 130,\n",
      "        134, 144, 154,   1, 130, 140,   1, 138, 160, 137, 154, 135, 140, 139,\n",
      "        126,   9,   1, 139, 160, 136, 140, 137, 134,   1, 139, 131,   1, 133,\n",
      "        128, 160, 142, 156, 131,   1, 149, 145, 132, 134, 138,   1, 140, 149,\n",
      "        126, 138,   1, 139, 126, 130, 133, 140, 142, 145,   1, 126, 139, 160,\n",
      "          1, 149, 145, 132, 134, 138,   1, 142, 145, 136, 126, 138,   1, 128,\n",
      "        134, 141, 137, 126, 144, 134,  11,   1, 114,   1, 139, 154, 140, 129,\n",
      "        140,   1, 128,   1,  99, 142, 140, 129, 140, 127, 134, 149, 160,   1,\n",
      "        143, 128, 140, 157,   1, 136, 126, 138, 131, 139, 134, 148, 157,   9,\n",
      "          1, 141, 140, 142, 157, 130, 139, 126,   9,   1, 139, 140, 128, 126,\n",
      "          9,   1, 157, 143, 139, 126,   9,   1, 163,   1, 143, 136, 126, 133,\n",
      "        126, 144, 134,   1, 139, 131,   1, 132, 126, 137, 154,  11,   1,  95,\n",
      "          1, 144, 145, 144,   1, 141, 142, 134, 147, 140, 130, 134, 144, 154,\n",
      "        143, 157,   1, 135, 140, 138, 145,   1, 139, 140, 149, 145, 128, 126,\n",
      "        144, 134,   1, 128,   1, 130, 131, 142, 131, 128,   5, 157, 139, 160,\n",
      "        138,   1, 130, 140, 138, 134, 136, 145,   9,   1, 143, 131, 142, 131,\n",
      "        130,   1, 138, 126, 129, 126, 133, 134, 139, 160, 128,   9,   1, 133,\n",
      "        126, 128, 126, 137, 131, 139, 134, 147,   1, 127, 140, 149, 136, 126,\n",
      "        138, 134,   1, 136, 134, 141,   5, 157, 149, 136, 134,   1, 144, 126,\n",
      "          1, 128, 131, 137, 134, 149, 131, 133, 139, 134, 138, 134,   1, 129,\n",
      "        142, 145, 130, 126, 138, 134,   1, 128, 140, 143, 136, 145,  11,   1,\n",
      "        110, 142, 126, 128, 130, 126,   9,   1, 144, 140, 135,   1, 130, 140,\n",
      "        138, 134, 136,   9,   1, 141, 140, 143, 144, 126, 128, 137, 131, 139,\n",
      "        134, 135,   1, 135, 140, 129, 140,   1, 136, 140, 150, 144, 140, 138,\n",
      "          9,   1, 128, 143, 131,  10, 144, 126, 136, 134,   1, 139, 126, 135,\n",
      "        141, 140, 142, 157, 130, 139, 160, 150, 134, 135,   1, 160,   1, 139,\n",
      "        126, 135, 136, 142, 126, 151, 131,   1, 141, 140, 137, 140, 132, 131,\n",
      "        139, 134, 135,   1, 139, 126,   1, 128, 131, 143, 154,   1,  96, 140,\n",
      "        142, 134, 143, 137, 126, 128,   9,   1, 163,   1, 126, 137, 131,   1,\n",
      "        133, 139, 140, 128,   1, 130, 126, 142, 138, 126,   1, 142, 160, 149,\n",
      "          1, 142, 160, 128, 139, 157, 144, 134,   1, 135, 140, 129, 140,   1,\n",
      "        130, 140,   1, 130, 142, 140, 129, 140, 127, 134, 148, 154, 136, 134,\n",
      "        147,   1, 127, 145, 130, 134, 139, 136, 160, 128,  11,   1, 116, 140,\n",
      "        144, 154,   1, 143, 144, 160, 139, 134,   1, 127, 160, 137, 160,   1,\n",
      "        160,   1, 128, 160, 136, 139, 126,   1, 157, 143, 139, 160,   9,   1,\n",
      "        144, 126,   1, 128, 134, 130,   1, 139, 126, 128, 136, 142, 145, 129,\n",
      "        134,   1, 143, 145, 138, 139, 134, 135,   9,   1, 141, 140, 139, 145,\n",
      "        142, 134, 135,   9,   1, 141, 140, 129, 126, 139, 134, 135,  23,   1,\n",
      "        136, 145, 141, 134,   1, 147, 128, 140, 142, 140, 143, 144, 145,   9,\n",
      "          1, 136, 145, 141, 134,   1, 129, 137, 134, 139, 134,   9,   1, 127,\n",
      "        142, 145, 130, 139, 160,   1, 138, 126, 129, 126, 133, 134, 139, 134,\n",
      "          1, 144, 126,   1, 151, 131,   1, 127, 142, 145, 130, 139, 160, 150,\n",
      "        160,   1, 141, 140, 138, 131, 150, 136, 126, 139, 139, 157,   1, 137,\n",
      "        156, 130, 143, 154, 136, 160,  11,   1, 108, 160,   1, 133, 131, 137,\n",
      "        131, 139, 160,   1, 143, 128, 160, 132, 140, 161,   9,   1, 139, 160,\n",
      "          1, 128, 134, 130, 145,   1, 128, 143, 138, 160, 147, 139, 131, 139,\n",
      "        140, 129, 140,   1, 139, 131,   1, 141, 140, 127, 126, 149, 134, 150,\n",
      "         11,   1,  97, 140, 133, 130, 145, 147,   1, 145, 130, 145, 150, 137,\n",
      "        134, 128, 134, 135,   9,   1, 133, 126, 129, 145, 143, 137, 134, 135,\n",
      "          1, 128, 160, 130,   1, 139, 126, 146, 144, 140, 128, 140, 129, 140,\n",
      "          1, 143, 140, 141, 145, 147, 145,  24,   1, 145,   1,  98, 131, 142,\n",
      "        138, 126, 139, 126,   1, 128])\n"
     ]
    }
   ],
   "source": [
    "# encoding the entire text dataset and store in into a torch tensor\n",
    "\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fc90850-179a-408f-b211-af218d0b127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up the data into train and validation sets\n",
    "\n",
    "n = int(0.9*len(data)) # first 90% is train data, rest is val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "082e8541-6f2d-4c2f-9fd5-29d71fac5bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28, 66, 52,  1, 54, 66, 65, 70, 71])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "874b55bf-ab4e-4e48-b12e-61cc442d05d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([28]) the target is: 66\n",
      "when input is tensor([28, 66]) the target is: 52\n",
      "when input is tensor([28, 66, 52]) the target is: 1\n",
      "when input is tensor([28, 66, 52,  1]) the target is: 54\n",
      "when input is tensor([28, 66, 52,  1, 54]) the target is: 66\n",
      "when input is tensor([28, 66, 52,  1, 54, 66]) the target is: 65\n",
      "when input is tensor([28, 66, 52,  1, 54, 66, 65]) the target is: 70\n",
      "when input is tensor([28, 66, 52,  1, 54, 66, 65, 70]) the target is: 71\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35e1adb2-1b5f-481a-831c-d59188f9ff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[160, 130, 141, 131, 136, 145, 128, 126],\n",
      "        [126, 143, 144, 159,   9,   1, 151, 126],\n",
      "        [  1, 128, 134, 143, 144, 126, 142, 149],\n",
      "        [126, 159, 144, 154, 143, 157,   1, 130]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[130, 141, 131, 136, 145, 128, 126, 128],\n",
      "        [143, 144, 159,   9,   1, 151, 126, 143],\n",
      "        [128, 134, 143, 144, 126, 142, 149, 126],\n",
      "        [159, 144, 154, 143, 157,   1, 130, 134]])\n",
      "---\n",
      "when input is [160] the target: 130\n",
      "when input is [160, 130] the target: 141\n",
      "when input is [160, 130, 141] the target: 131\n",
      "when input is [160, 130, 141, 131] the target: 136\n",
      "when input is [160, 130, 141, 131, 136] the target: 145\n",
      "when input is [160, 130, 141, 131, 136, 145] the target: 128\n",
      "when input is [160, 130, 141, 131, 136, 145, 128] the target: 126\n",
      "when input is [160, 130, 141, 131, 136, 145, 128, 126] the target: 128\n",
      "when input is [126] the target: 143\n",
      "when input is [126, 143] the target: 144\n",
      "when input is [126, 143, 144] the target: 159\n",
      "when input is [126, 143, 144, 159] the target: 9\n",
      "when input is [126, 143, 144, 159, 9] the target: 1\n",
      "when input is [126, 143, 144, 159, 9, 1] the target: 151\n",
      "when input is [126, 143, 144, 159, 9, 1, 151] the target: 126\n",
      "when input is [126, 143, 144, 159, 9, 1, 151, 126] the target: 143\n",
      "when input is [1] the target: 128\n",
      "when input is [1, 128] the target: 134\n",
      "when input is [1, 128, 134] the target: 143\n",
      "when input is [1, 128, 134, 143] the target: 144\n",
      "when input is [1, 128, 134, 143, 144] the target: 126\n",
      "when input is [1, 128, 134, 143, 144, 126] the target: 142\n",
      "when input is [1, 128, 134, 143, 144, 126, 142] the target: 149\n",
      "when input is [1, 128, 134, 143, 144, 126, 142, 149] the target: 126\n",
      "when input is [126] the target: 159\n",
      "when input is [126, 159] the target: 144\n",
      "when input is [126, 159, 144] the target: 154\n",
      "when input is [126, 159, 144, 154] the target: 143\n",
      "when input is [126, 159, 144, 154, 143] the target: 157\n",
      "when input is [126, 159, 144, 154, 143, 157] the target: 1\n",
      "when input is [126, 159, 144, 154, 143, 157, 1] the target: 130\n",
      "when input is [126, 159, 144, 154, 143, 157, 1, 130] the target: 134\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1999)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the max context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('---')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4634f6d-7838-4901-8141-bfa00ac0b1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[160, 130, 141, 131, 136, 145, 128, 126],\n",
      "        [126, 143, 144, 159,   9,   1, 151, 126],\n",
      "        [  1, 128, 134, 143, 144, 126, 142, 149],\n",
      "        [126, 159, 144, 154, 143, 157,   1, 130]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6f045ca-d4a0-4f20-97f2-08ea5503fe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 171])\n",
      "tensor(5.6773, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "mФз=ш67шbьAЄюЗPr}єУБüFšч-\n",
      "LкГЕ5ЇШnl=лZБ-ЩЭмЯХš3ь‘їМiіCSAOtВЭр(М(ЦśnłА9FЖЖNh/áü[áМмш’!_П…́aäЩРAJr=лn^\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1999)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range (max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes B, C\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bf6038d-bd35-417e-b6d6-4113fec44a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a683e8f-8608-4bbf-8bea-be43e6d67f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4950947761535645\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    #evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01c36f21-852c-45d9-9580-e781d6e0341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "УCsż[ютося.\n",
      "— пріня, іда кум ве гобумупі влю хосвстрогоб таżаро?\n",
      "Якобейоленькувкогродниливіви тихо То-чаву мимій спим ї шHПо сту, гоно ї кокупалови, тиїї дагоку в кули: стомор заве.\n",
      "Додо маго муле нобу яюаро ві ріся йобмиціша ск кідо зисті. сіле7l/послюви до ся? киміся ін по впрившімух Прідцероя.\n",
      "V\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype = torch.long), max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb42ec9-4d0c-4697-bc3e-4a621d5fb77c",
   "metadata": {},
   "source": [
    "# The mathemtical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88c8177d-92f1-4551-a79e-0d2d59b5215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy example:\n",
    "\n",
    "torch.manual_seed(1999)\n",
    "B,T,C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fd45968-0030-449c-920f-1a3978a379b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1b072b1-3778-4f47-936f-18c9c6d603cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2811,  0.4112],\n",
       "        [ 0.3499,  1.2606],\n",
       "        [ 0.3096, -1.3506],\n",
       "        [-0.1291,  0.1212],\n",
       "        [-0.2857, -0.8869],\n",
       "        [ 0.1041, -0.4780],\n",
       "        [ 1.4055, -1.4495],\n",
       "        [ 1.8769, -0.3176]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0ecfd5b-deab-4aa7-a473-8982960387e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2811,  0.4112],\n",
       "        [ 0.3155,  0.8359],\n",
       "        [ 0.3135,  0.1071],\n",
       "        [ 0.2029,  0.1106],\n",
       "        [ 0.1052, -0.0889],\n",
       "        [ 0.1050, -0.1537],\n",
       "        [ 0.2908, -0.3388],\n",
       "        [ 0.4890, -0.3362]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33cbd478-b982-4fdc-b293-27ab1c082ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "080fab36-c27e-40b6-bed0-7ec008e24c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei/wei.sum(1,keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4de22aca-e2d4-4a7d-b0ce-08d992f858c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92dfd2-385a-4a16-9bc8-4640562435ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9152bff2-f511-4f9c-a9b9-ad0fa248d432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2811,  0.4112],\n",
       "         [ 0.3155,  0.8359],\n",
       "         [ 0.3135,  0.1071],\n",
       "         [ 0.2029,  0.1106],\n",
       "         [ 0.1052, -0.0889],\n",
       "         [ 0.1050, -0.1537],\n",
       "         [ 0.2908, -0.3388],\n",
       "         [ 0.4890, -0.3362]]),\n",
       " tensor([[ 0.2811,  0.4112],\n",
       "         [ 0.3155,  0.8359],\n",
       "         [ 0.3135,  0.1071],\n",
       "         [ 0.2029,  0.1106],\n",
       "         [ 0.1052, -0.0889],\n",
       "         [ 0.1050, -0.1537],\n",
       "         [ 0.2908, -0.3388],\n",
       "         [ 0.4890, -0.3362]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c765c4b9-2a2c-4086-b2cf-097ac6969010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d4223a7-1539-406b-b454-f187e281ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09c9d339-5510-4993-9b71-d49257c7e378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention\n",
    "torch.manual_seed(1999)\n",
    "B, T, C  = 4, 8, 32 # batch, time, channels\n",
    "x = torch.randn(B, T, C) \n",
    "\n",
    "# let's see a single head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "# out = wei @ v\n",
    "out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dea40aa9-7324-4d2b-9358-9f9f4f46d7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.7929e-01, 7.2071e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [6.1315e-01, 2.6986e-01, 1.1699e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [6.7289e-02, 2.6367e-01, 8.3458e-02, 5.8558e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [8.0920e-02, 6.0674e-03, 6.9663e-01, 3.9375e-02, 1.7701e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.4540e-01, 6.0001e-03, 4.6113e-01, 4.7113e-02, 1.1557e-01, 2.2479e-01,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.5877e-01, 2.3713e-02, 1.7820e-01, 8.8063e-02, 5.7497e-02, 3.2605e-01,\n",
       "         1.6771e-01, 0.0000e+00],\n",
       "        [6.6818e-03, 8.7353e-01, 2.6585e-04, 1.9003e-02, 1.6669e-02, 5.9498e-03,\n",
       "         6.1439e-02, 1.6461e-02]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94867a5d-0faf-42a6-a66b-18319598a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b72275d6-4e24-49f3-a60b-650c6a58530d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0054)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6dad2586-cdf6-4db2-9d41-1e06b45df74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0939)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "698414ba-289f-4d5e-949e-ccb48ede19bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0153)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4029064e-59d4-4fba-8874-fe9966be1e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c91929e4-ee53-487e-9cf2-f260804cc326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]) * 8, dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
